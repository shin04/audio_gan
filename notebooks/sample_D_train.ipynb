{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f6cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "\n",
    "from models.Generator import Generator\n",
    "from models.Discriminator import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe7efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/piano/**/*.wav\"\n",
    "batch_size = 16\n",
    "z_dim = 100\n",
    "n_epoch = 100\n",
    "lr = 0.0001\n",
    "sampling_rate = 16000\n",
    "D_learn_perG_lean = 5\n",
    "generate_sounds_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19475b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "for path in glob.glob(data_path, recursive=True):\n",
    "    path_list.append(path)\n",
    "    # print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f73c5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ファイルの時間を確認\n",
    "# s = 0\n",
    "# for path in path_list:\n",
    "#     y, sr = librosa.load(path)\n",
    "#     sec = len(y)/sr\n",
    "#     n = int(sec/generate_sounds_interval)\n",
    "#     s += n\n",
    "#     print(\"{}: {}[sec], {}\".format(path, sec, n))\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61cb61af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:43<00:00,  5.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# データをgenerate_sounds_interval秒単位に分割\n",
    "wave_data = []\n",
    "# labels = []\n",
    "for path in tqdm(path_list):\n",
    "#     label = path.split('/')[2]\n",
    "    raw_wave, sr = librosa.load(path)\n",
    "    for i in range(0, len(raw_wave), generate_sounds_interval*sr):\n",
    "        # 時間が足りないものは弾く\n",
    "        if i+generate_sounds_interval*sr > len(raw_wave):\n",
    "            continue\n",
    "        wave_data.append(raw_wave[i:i+generate_sounds_interval*sr])\n",
    "#         labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b37e360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = wave_data[0].shape\n",
    "for i, w in enumerate(wave_data):\n",
    "    if w.shape != shape:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b2716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        assert len(data) == len(labels)\n",
    "        \n",
    "        for i, d in tqdm(enumerate(data)):\n",
    "            melspec = librosa.feature.melspectrogram(y=d, sr=sr)\n",
    "            melspec_db = librosa.power_to_db(melspec, ref=np.max)\n",
    "            self.data.append(melspec_db)\n",
    "            self.labels.append(float(labels[i]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479d22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1590it [00:07, 223.53it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = np.random.randint(0, 2, size = len(wave_data))\n",
    "data = MyData(wave_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f891b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7aa09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_D = Discriminator()\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(net_D.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bea9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 1, 128, 44]              10\n",
      "              ReLU-2           [-1, 1, 128, 44]               0\n",
      "         MaxPool2d-3           [-1, 1, 128, 44]               0\n",
      "            Linear-4                 [-1, 1024]       5,768,192\n",
      "           Dropout-5                 [-1, 1024]               0\n",
      "         LayerNorm-6               [-1, 4, 256]             512\n",
      "            Linear-7              [-1, 4, 1024]         263,168\n",
      "             Swish-8              [-1, 4, 1024]               0\n",
      "           Dropout-9              [-1, 4, 1024]               0\n",
      "           Linear-10               [-1, 4, 256]         262,400\n",
      "          Dropout-11               [-1, 4, 256]               0\n",
      "      FeedForward-12               [-1, 4, 256]               0\n",
      "          PreNorm-13               [-1, 4, 256]               0\n",
      "            Scale-14               [-1, 4, 256]               0\n",
      "        LayerNorm-15               [-1, 4, 256]             512\n",
      "           Linear-16               [-1, 4, 512]         131,072\n",
      "           Linear-17              [-1, 4, 1024]         262,144\n",
      "        Embedding-18                [-1, 4, 64]          65,600\n",
      "           Linear-19               [-1, 4, 256]         131,328\n",
      "          Dropout-20               [-1, 4, 256]               0\n",
      "        Attention-21               [-1, 4, 256]               0\n",
      "          PreNorm-22               [-1, 4, 256]               0\n",
      "        LayerNorm-23               [-1, 4, 256]             512\n",
      "        Rearrange-24               [-1, 256, 4]               0\n",
      "           Conv1d-25              [-1, 1024, 4]         263,168\n",
      "              GLU-26               [-1, 512, 4]               0\n",
      "           Conv1d-27               [-1, 512, 4]          16,384\n",
      "  DepthWiseConv1d-28               [-1, 512, 4]               0\n",
      "      BatchNorm1d-29               [-1, 512, 4]           1,024\n",
      "            Swish-30               [-1, 512, 4]               0\n",
      "           Conv1d-31               [-1, 256, 4]         131,328\n",
      "        Rearrange-32               [-1, 4, 256]               0\n",
      "          Dropout-33               [-1, 4, 256]               0\n",
      "ConformerConvModule-34               [-1, 4, 256]               0\n",
      "        LayerNorm-35               [-1, 4, 256]             512\n",
      "           Linear-36              [-1, 4, 1024]         263,168\n",
      "            Swish-37              [-1, 4, 1024]               0\n",
      "          Dropout-38              [-1, 4, 1024]               0\n",
      "           Linear-39               [-1, 4, 256]         262,400\n",
      "          Dropout-40               [-1, 4, 256]               0\n",
      "      FeedForward-41               [-1, 4, 256]               0\n",
      "          PreNorm-42               [-1, 4, 256]               0\n",
      "            Scale-43               [-1, 4, 256]               0\n",
      "        LayerNorm-44               [-1, 4, 256]             512\n",
      "   ConformerBlock-45               [-1, 4, 256]               0\n",
      "        LayerNorm-46               [-1, 4, 256]             512\n",
      "           Linear-47              [-1, 4, 1024]         263,168\n",
      "            Swish-48              [-1, 4, 1024]               0\n",
      "          Dropout-49              [-1, 4, 1024]               0\n",
      "           Linear-50               [-1, 4, 256]         262,400\n",
      "          Dropout-51               [-1, 4, 256]               0\n",
      "      FeedForward-52               [-1, 4, 256]               0\n",
      "          PreNorm-53               [-1, 4, 256]               0\n",
      "            Scale-54               [-1, 4, 256]               0\n",
      "        LayerNorm-55               [-1, 4, 256]             512\n",
      "           Linear-56               [-1, 4, 512]         131,072\n",
      "           Linear-57              [-1, 4, 1024]         262,144\n",
      "        Embedding-58                [-1, 4, 64]          65,600\n",
      "           Linear-59               [-1, 4, 256]         131,328\n",
      "          Dropout-60               [-1, 4, 256]               0\n",
      "        Attention-61               [-1, 4, 256]               0\n",
      "          PreNorm-62               [-1, 4, 256]               0\n",
      "        LayerNorm-63               [-1, 4, 256]             512\n",
      "        Rearrange-64               [-1, 256, 4]               0\n",
      "           Conv1d-65              [-1, 1024, 4]         263,168\n",
      "              GLU-66               [-1, 512, 4]               0\n",
      "           Conv1d-67               [-1, 512, 4]          16,384\n",
      "  DepthWiseConv1d-68               [-1, 512, 4]               0\n",
      "      BatchNorm1d-69               [-1, 512, 4]           1,024\n",
      "            Swish-70               [-1, 512, 4]               0\n",
      "           Conv1d-71               [-1, 256, 4]         131,328\n",
      "        Rearrange-72               [-1, 4, 256]               0\n",
      "          Dropout-73               [-1, 4, 256]               0\n",
      "ConformerConvModule-74               [-1, 4, 256]               0\n",
      "        LayerNorm-75               [-1, 4, 256]             512\n",
      "           Linear-76              [-1, 4, 1024]         263,168\n",
      "            Swish-77              [-1, 4, 1024]               0\n",
      "          Dropout-78              [-1, 4, 1024]               0\n",
      "           Linear-79               [-1, 4, 256]         262,400\n",
      "          Dropout-80               [-1, 4, 256]               0\n",
      "      FeedForward-81               [-1, 4, 256]               0\n",
      "          PreNorm-82               [-1, 4, 256]               0\n",
      "            Scale-83               [-1, 4, 256]               0\n",
      "        LayerNorm-84               [-1, 4, 256]             512\n",
      "   ConformerBlock-85               [-1, 4, 256]               0\n",
      "        LayerNorm-86               [-1, 4, 256]             512\n",
      "           Linear-87              [-1, 4, 1024]         263,168\n",
      "            Swish-88              [-1, 4, 1024]               0\n",
      "          Dropout-89              [-1, 4, 1024]               0\n",
      "           Linear-90               [-1, 4, 256]         262,400\n",
      "          Dropout-91               [-1, 4, 256]               0\n",
      "      FeedForward-92               [-1, 4, 256]               0\n",
      "          PreNorm-93               [-1, 4, 256]               0\n",
      "            Scale-94               [-1, 4, 256]               0\n",
      "        LayerNorm-95               [-1, 4, 256]             512\n",
      "           Linear-96               [-1, 4, 512]         131,072\n",
      "           Linear-97              [-1, 4, 1024]         262,144\n",
      "        Embedding-98                [-1, 4, 64]          65,600\n",
      "           Linear-99               [-1, 4, 256]         131,328\n",
      "         Dropout-100               [-1, 4, 256]               0\n",
      "       Attention-101               [-1, 4, 256]               0\n",
      "         PreNorm-102               [-1, 4, 256]               0\n",
      "       LayerNorm-103               [-1, 4, 256]             512\n",
      "       Rearrange-104               [-1, 256, 4]               0\n",
      "          Conv1d-105              [-1, 1024, 4]         263,168\n",
      "             GLU-106               [-1, 512, 4]               0\n",
      "          Conv1d-107               [-1, 512, 4]          16,384\n",
      " DepthWiseConv1d-108               [-1, 512, 4]               0\n",
      "     BatchNorm1d-109               [-1, 512, 4]           1,024\n",
      "           Swish-110               [-1, 512, 4]               0\n",
      "          Conv1d-111               [-1, 256, 4]         131,328\n",
      "       Rearrange-112               [-1, 4, 256]               0\n",
      "         Dropout-113               [-1, 4, 256]               0\n",
      "ConformerConvModule-114               [-1, 4, 256]               0\n",
      "       LayerNorm-115               [-1, 4, 256]             512\n",
      "          Linear-116              [-1, 4, 1024]         263,168\n",
      "           Swish-117              [-1, 4, 1024]               0\n",
      "         Dropout-118              [-1, 4, 1024]               0\n",
      "          Linear-119               [-1, 4, 256]         262,400\n",
      "         Dropout-120               [-1, 4, 256]               0\n",
      "     FeedForward-121               [-1, 4, 256]               0\n",
      "         PreNorm-122               [-1, 4, 256]               0\n",
      "           Scale-123               [-1, 4, 256]               0\n",
      "       LayerNorm-124               [-1, 4, 256]             512\n",
      "  ConformerBlock-125               [-1, 4, 256]               0\n",
      "          Linear-126                    [-1, 1]           1,025\n",
      "         Sigmoid-127                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,936,459\n",
      "Trainable params: 11,936,459\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.77\n",
      "Params size (MB): 45.53\n",
      "Estimated Total Size (MB): 47.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net_D, (1, 128, 44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27e6648f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-80db79d35393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ConformerGAN/ConformerGAN_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ConformerGAN/ConformerGAN_env/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ConformerGAN/ConformerGAN_env/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(n_epoch):\n",
    "    # training\n",
    "    train_losses = 0\n",
    "    for d in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x, y = d\n",
    "        x = x.unsqueeze(1)\n",
    "        output = net_D(x).view(-1)\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses += loss.item()\n",
    "        \n",
    "    # validation\n",
    "    test_losses = 0\n",
    "    actual_list, pred_list = [], []\n",
    "    for data in data_loader:\n",
    "        with torch.no_grad():\n",
    "            x, y = data\n",
    "            x = x.unsqueeze(1)\n",
    "            output = net_D(x).view(-1)\n",
    "            loss = loss_function(output, y)\n",
    "            _, y_pred = torch.max(output, 1)\n",
    "            test_losses += loss.item()\n",
    "\n",
    "            actual_list.append(y.cpu().numpy())\n",
    "            pred_list.append(y_pred.cpu().numpy())\n",
    "    \n",
    "    actual_list = np.concatenate(actual_list)\n",
    "    pred_list = np.concatenate(pred_list)\n",
    "    accuracy = np.mean(actual_list == pred_list)\n",
    "\n",
    "    print(\"epoch\", epoch, \"\\t train_loss\", train_losses, \"\\t test_loss\", test_losses, \"\\t accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37881d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5336, 0.4634, 0.5175, 0.5143, 0.5132, 0.4794, 0.4304, 0.4368, 0.4511,\n",
       "        0.5093, 0.6383, 0.5524, 0.4577, 0.4327, 0.5663, 0.3983, 0.4929, 0.5776,\n",
       "        0.2837, 0.3752, 0.5219, 0.5273, 0.6529, 0.5802, 0.6046, 0.5144, 0.5148,\n",
       "        0.4257, 0.3903, 0.5113, 0.4560, 0.4466], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c174a6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034c56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ConformerGAN",
   "language": "python",
   "name": "conformergan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
