{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ec67fd",
   "metadata": {},
   "source": [
    "# GAN training sample\n",
    "Generator: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72886bc0",
   "metadata": {},
   "source": [
    "## import libraries and configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6cc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "\n",
    "from models.Generator import Generator\n",
    "from models.Discriminator import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f224cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/piano/**/*.wav\"\n",
    "batch_size = 32\n",
    "z_dim = 100\n",
    "n_epoch = 100\n",
    "lr = 0.0001\n",
    "sampling_rate = 16000\n",
    "# learn_pecentage = 5 # G１回の学習に対してDを何回学習させるか\n",
    "generate_sounds_interval = 1 # 5秒の音を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64c895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "#GPUが使用可能かどうか確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f518c",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0126129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "for path in glob.glob(data_path, recursive=True):\n",
    "    path_list.append(path)\n",
    "    # print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd092da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 各ファイルの時間を確認\n",
    "# s = 0\n",
    "# for path in path_list:\n",
    "#     y, sr = librosa.load(path)\n",
    "#     sec = len(y)/sr\n",
    "#     n = int(sec/generate_sounds_interval)\n",
    "#     s += n\n",
    "#     print(\"{}: {}[sec], {}\".format(path, sec, n))\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79737392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:08<00:00,  3.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# データをgenerate_sounds_interval秒単位に分割\n",
    "wave_data = []\n",
    "for path in tqdm(path_list):\n",
    "    raw_wave, sr = librosa.load(path)\n",
    "    for i in range(0, len(raw_wave), generate_sounds_interval*sr):\n",
    "        # 時間が足りないものは弾く\n",
    "        if i+generate_sounds_interval*sr > len(raw_wave):\n",
    "            continue\n",
    "        wave_data.append(raw_wave[i:i+generate_sounds_interval*sr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f715d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = []\n",
    "        \n",
    "        for i, d in tqdm(enumerate(data)):\n",
    "            melspec = librosa.feature.melspectrogram(y=d, sr=sr)\n",
    "            melspec_db = librosa.power_to_db(melspec, ref=np.max)\n",
    "            self.data.append(melspec_db)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e4353a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1590it [00:06, 246.48it/s]\n"
     ]
    }
   ],
   "source": [
    "data = GanDataset(wave_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41e8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c860492",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd27746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  torch.Size([2, 100])\n",
      "0.005585908889770508\n",
      "l1: torch.Size([2, 5632])\n",
      "0.00016498565673828125\n",
      "l1 -> reshape: torch.Size([2, 352, 16])\n",
      "blk1-0: torch.Size([2, 352, 16])\n",
      "0.045564889907836914\n",
      "blk2-0 upscale: torch.Size([2, 1408, 4])\n",
      "0.0009160041809082031\n",
      "blk2-0: torch.Size([2, 1408, 4])\n",
      "1.37642502784729\n",
      "blk2-1 upscale: torch.Size([2, 5632, 1])\n",
      "0.0011420249938964844\n",
      "blk2-1: torch.Size([2, 5632, 1])\n",
      "80.64254975318909\n",
      "torch.Size([2, 1, 5632])\n",
      "torch.Size([2, 1, 128, 44])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 5632]         568,832\n",
      "         LayerNorm-2              [-1, 352, 16]              32\n",
      "            Linear-3              [-1, 352, 64]           1,088\n",
      "             Swish-4              [-1, 352, 64]               0\n",
      "           Dropout-5              [-1, 352, 64]               0\n",
      "            Linear-6              [-1, 352, 16]           1,040\n",
      "           Dropout-7              [-1, 352, 16]               0\n",
      "       FeedForward-8              [-1, 352, 16]               0\n",
      "           PreNorm-9              [-1, 352, 16]               0\n",
      "            Scale-10              [-1, 352, 16]               0\n",
      "        LayerNorm-11              [-1, 352, 16]              32\n",
      "           Linear-12             [-1, 352, 512]           8,192\n",
      "           Linear-13            [-1, 352, 1024]          16,384\n",
      "        Embedding-14              [-1, 352, 64]          65,600\n",
      "           Linear-15              [-1, 352, 16]           8,208\n",
      "          Dropout-16              [-1, 352, 16]               0\n",
      "        Attention-17              [-1, 352, 16]               0\n",
      "          PreNorm-18              [-1, 352, 16]               0\n",
      "        LayerNorm-19              [-1, 352, 16]              32\n",
      "        Rearrange-20              [-1, 16, 352]               0\n",
      "           Conv1d-21              [-1, 64, 352]           1,088\n",
      "              GLU-22              [-1, 32, 352]               0\n",
      "           Conv1d-23              [-1, 32, 352]           1,024\n",
      "  DepthWiseConv1d-24              [-1, 32, 352]               0\n",
      "      BatchNorm1d-25              [-1, 32, 352]              64\n",
      "            Swish-26              [-1, 32, 352]               0\n",
      "           Conv1d-27              [-1, 16, 352]             528\n",
      "        Rearrange-28              [-1, 352, 16]               0\n",
      "          Dropout-29              [-1, 352, 16]               0\n",
      "ConformerConvModule-30              [-1, 352, 16]               0\n",
      "        LayerNorm-31              [-1, 352, 16]              32\n",
      "           Linear-32              [-1, 352, 64]           1,088\n",
      "            Swish-33              [-1, 352, 64]               0\n",
      "          Dropout-34              [-1, 352, 64]               0\n",
      "           Linear-35              [-1, 352, 16]           1,040\n",
      "          Dropout-36              [-1, 352, 16]               0\n",
      "      FeedForward-37              [-1, 352, 16]               0\n",
      "          PreNorm-38              [-1, 352, 16]               0\n",
      "            Scale-39              [-1, 352, 16]               0\n",
      "        LayerNorm-40              [-1, 352, 16]              32\n",
      "   ConformerBlock-41              [-1, 352, 16]               0\n",
      "        LayerNorm-42              [-1, 1408, 4]               8\n",
      "           Linear-43             [-1, 1408, 16]              80\n",
      "            Swish-44             [-1, 1408, 16]               0\n",
      "          Dropout-45             [-1, 1408, 16]               0\n",
      "           Linear-46              [-1, 1408, 4]              68\n",
      "          Dropout-47              [-1, 1408, 4]               0\n",
      "      FeedForward-48              [-1, 1408, 4]               0\n",
      "          PreNorm-49              [-1, 1408, 4]               0\n",
      "            Scale-50              [-1, 1408, 4]               0\n",
      "        LayerNorm-51              [-1, 1408, 4]               8\n",
      "           Linear-52            [-1, 1408, 512]           2,048\n",
      "           Linear-53           [-1, 1408, 1024]           4,096\n",
      "        Embedding-54             [-1, 1408, 64]          65,600\n",
      "           Linear-55              [-1, 1408, 4]           2,052\n",
      "          Dropout-56              [-1, 1408, 4]               0\n",
      "        Attention-57              [-1, 1408, 4]               0\n",
      "          PreNorm-58              [-1, 1408, 4]               0\n",
      "        LayerNorm-59              [-1, 1408, 4]               8\n",
      "        Rearrange-60              [-1, 4, 1408]               0\n",
      "           Conv1d-61             [-1, 16, 1408]              80\n",
      "              GLU-62              [-1, 8, 1408]               0\n",
      "           Conv1d-63              [-1, 8, 1408]             256\n",
      "  DepthWiseConv1d-64              [-1, 8, 1408]               0\n",
      "      BatchNorm1d-65              [-1, 8, 1408]              16\n",
      "            Swish-66              [-1, 8, 1408]               0\n",
      "           Conv1d-67              [-1, 4, 1408]              36\n",
      "        Rearrange-68              [-1, 1408, 4]               0\n",
      "          Dropout-69              [-1, 1408, 4]               0\n",
      "ConformerConvModule-70              [-1, 1408, 4]               0\n",
      "        LayerNorm-71              [-1, 1408, 4]               8\n",
      "           Linear-72             [-1, 1408, 16]              80\n",
      "            Swish-73             [-1, 1408, 16]               0\n",
      "          Dropout-74             [-1, 1408, 16]               0\n",
      "           Linear-75              [-1, 1408, 4]              68\n",
      "          Dropout-76              [-1, 1408, 4]               0\n",
      "      FeedForward-77              [-1, 1408, 4]               0\n",
      "          PreNorm-78              [-1, 1408, 4]               0\n",
      "            Scale-79              [-1, 1408, 4]               0\n",
      "        LayerNorm-80              [-1, 1408, 4]               8\n",
      "   ConformerBlock-81              [-1, 1408, 4]               0\n",
      "        LayerNorm-82              [-1, 5632, 1]               2\n",
      "           Linear-83              [-1, 5632, 4]               8\n",
      "            Swish-84              [-1, 5632, 4]               0\n",
      "          Dropout-85              [-1, 5632, 4]               0\n",
      "           Linear-86              [-1, 5632, 1]               5\n",
      "          Dropout-87              [-1, 5632, 1]               0\n",
      "      FeedForward-88              [-1, 5632, 1]               0\n",
      "          PreNorm-89              [-1, 5632, 1]               0\n",
      "            Scale-90              [-1, 5632, 1]               0\n",
      "        LayerNorm-91              [-1, 5632, 1]               2\n",
      "           Linear-92            [-1, 5632, 512]             512\n",
      "           Linear-93           [-1, 5632, 1024]           1,024\n",
      "        Embedding-94             [-1, 5632, 64]          65,600\n",
      "           Linear-95              [-1, 5632, 1]             513\n",
      "          Dropout-96              [-1, 5632, 1]               0\n",
      "        Attention-97              [-1, 5632, 1]               0\n",
      "          PreNorm-98              [-1, 5632, 1]               0\n",
      "        LayerNorm-99              [-1, 5632, 1]               2\n",
      "       Rearrange-100              [-1, 1, 5632]               0\n",
      "          Conv1d-101              [-1, 4, 5632]               8\n",
      "             GLU-102              [-1, 2, 5632]               0\n",
      "          Conv1d-103              [-1, 2, 5632]              64\n",
      " DepthWiseConv1d-104              [-1, 2, 5632]               0\n",
      "     BatchNorm1d-105              [-1, 2, 5632]               4\n",
      "           Swish-106              [-1, 2, 5632]               0\n",
      "          Conv1d-107              [-1, 1, 5632]               3\n",
      "       Rearrange-108              [-1, 5632, 1]               0\n",
      "         Dropout-109              [-1, 5632, 1]               0\n",
      "ConformerConvModule-110              [-1, 5632, 1]               0\n",
      "       LayerNorm-111              [-1, 5632, 1]               2\n",
      "          Linear-112              [-1, 5632, 4]               8\n",
      "           Swish-113              [-1, 5632, 4]               0\n",
      "         Dropout-114              [-1, 5632, 4]               0\n",
      "          Linear-115              [-1, 5632, 1]               5\n",
      "         Dropout-116              [-1, 5632, 1]               0\n",
      "     FeedForward-117              [-1, 5632, 1]               0\n",
      "         PreNorm-118              [-1, 5632, 1]               0\n",
      "           Scale-119              [-1, 5632, 1]               0\n",
      "       LayerNorm-120              [-1, 5632, 1]               2\n",
      "  ConformerBlock-121              [-1, 5632, 1]               0\n",
      "          Conv2d-122           [-1, 1, 128, 44]               2\n",
      "================================================================\n",
      "Total params: 816,622\n",
      "Trainable params: 816,622\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 98.44\n",
      "Params size (MB): 3.12\n",
      "Estimated Total Size (MB): 101.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net_G = Generator()\n",
    "summary(net_G, (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959cf4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 1, 128, 44]              10\n",
      "              ReLU-2           [-1, 1, 128, 44]               0\n",
      "         MaxPool2d-3           [-1, 1, 128, 44]               0\n",
      "            Linear-4                 [-1, 1024]       5,768,192\n",
      "           Dropout-5                 [-1, 1024]               0\n",
      "         LayerNorm-6               [-1, 4, 256]             512\n",
      "            Linear-7              [-1, 4, 1024]         263,168\n",
      "             Swish-8              [-1, 4, 1024]               0\n",
      "           Dropout-9              [-1, 4, 1024]               0\n",
      "           Linear-10               [-1, 4, 256]         262,400\n",
      "          Dropout-11               [-1, 4, 256]               0\n",
      "      FeedForward-12               [-1, 4, 256]               0\n",
      "          PreNorm-13               [-1, 4, 256]               0\n",
      "            Scale-14               [-1, 4, 256]               0\n",
      "        LayerNorm-15               [-1, 4, 256]             512\n",
      "           Linear-16               [-1, 4, 512]         131,072\n",
      "           Linear-17              [-1, 4, 1024]         262,144\n",
      "        Embedding-18                [-1, 4, 64]          65,600\n",
      "           Linear-19               [-1, 4, 256]         131,328\n",
      "          Dropout-20               [-1, 4, 256]               0\n",
      "        Attention-21               [-1, 4, 256]               0\n",
      "          PreNorm-22               [-1, 4, 256]               0\n",
      "        LayerNorm-23               [-1, 4, 256]             512\n",
      "        Rearrange-24               [-1, 256, 4]               0\n",
      "           Conv1d-25              [-1, 1024, 4]         263,168\n",
      "              GLU-26               [-1, 512, 4]               0\n",
      "           Conv1d-27               [-1, 512, 4]          16,384\n",
      "  DepthWiseConv1d-28               [-1, 512, 4]               0\n",
      "      BatchNorm1d-29               [-1, 512, 4]           1,024\n",
      "            Swish-30               [-1, 512, 4]               0\n",
      "           Conv1d-31               [-1, 256, 4]         131,328\n",
      "        Rearrange-32               [-1, 4, 256]               0\n",
      "          Dropout-33               [-1, 4, 256]               0\n",
      "ConformerConvModule-34               [-1, 4, 256]               0\n",
      "        LayerNorm-35               [-1, 4, 256]             512\n",
      "           Linear-36              [-1, 4, 1024]         263,168\n",
      "            Swish-37              [-1, 4, 1024]               0\n",
      "          Dropout-38              [-1, 4, 1024]               0\n",
      "           Linear-39               [-1, 4, 256]         262,400\n",
      "          Dropout-40               [-1, 4, 256]               0\n",
      "      FeedForward-41               [-1, 4, 256]               0\n",
      "          PreNorm-42               [-1, 4, 256]               0\n",
      "            Scale-43               [-1, 4, 256]               0\n",
      "        LayerNorm-44               [-1, 4, 256]             512\n",
      "   ConformerBlock-45               [-1, 4, 256]               0\n",
      "        LayerNorm-46               [-1, 4, 256]             512\n",
      "           Linear-47              [-1, 4, 1024]         263,168\n",
      "            Swish-48              [-1, 4, 1024]               0\n",
      "          Dropout-49              [-1, 4, 1024]               0\n",
      "           Linear-50               [-1, 4, 256]         262,400\n",
      "          Dropout-51               [-1, 4, 256]               0\n",
      "      FeedForward-52               [-1, 4, 256]               0\n",
      "          PreNorm-53               [-1, 4, 256]               0\n",
      "            Scale-54               [-1, 4, 256]               0\n",
      "        LayerNorm-55               [-1, 4, 256]             512\n",
      "           Linear-56               [-1, 4, 512]         131,072\n",
      "           Linear-57              [-1, 4, 1024]         262,144\n",
      "        Embedding-58                [-1, 4, 64]          65,600\n",
      "           Linear-59               [-1, 4, 256]         131,328\n",
      "          Dropout-60               [-1, 4, 256]               0\n",
      "        Attention-61               [-1, 4, 256]               0\n",
      "          PreNorm-62               [-1, 4, 256]               0\n",
      "        LayerNorm-63               [-1, 4, 256]             512\n",
      "        Rearrange-64               [-1, 256, 4]               0\n",
      "           Conv1d-65              [-1, 1024, 4]         263,168\n",
      "              GLU-66               [-1, 512, 4]               0\n",
      "           Conv1d-67               [-1, 512, 4]          16,384\n",
      "  DepthWiseConv1d-68               [-1, 512, 4]               0\n",
      "      BatchNorm1d-69               [-1, 512, 4]           1,024\n",
      "            Swish-70               [-1, 512, 4]               0\n",
      "           Conv1d-71               [-1, 256, 4]         131,328\n",
      "        Rearrange-72               [-1, 4, 256]               0\n",
      "          Dropout-73               [-1, 4, 256]               0\n",
      "ConformerConvModule-74               [-1, 4, 256]               0\n",
      "        LayerNorm-75               [-1, 4, 256]             512\n",
      "           Linear-76              [-1, 4, 1024]         263,168\n",
      "            Swish-77              [-1, 4, 1024]               0\n",
      "          Dropout-78              [-1, 4, 1024]               0\n",
      "           Linear-79               [-1, 4, 256]         262,400\n",
      "          Dropout-80               [-1, 4, 256]               0\n",
      "      FeedForward-81               [-1, 4, 256]               0\n",
      "          PreNorm-82               [-1, 4, 256]               0\n",
      "            Scale-83               [-1, 4, 256]               0\n",
      "        LayerNorm-84               [-1, 4, 256]             512\n",
      "   ConformerBlock-85               [-1, 4, 256]               0\n",
      "        LayerNorm-86               [-1, 4, 256]             512\n",
      "           Linear-87              [-1, 4, 1024]         263,168\n",
      "            Swish-88              [-1, 4, 1024]               0\n",
      "          Dropout-89              [-1, 4, 1024]               0\n",
      "           Linear-90               [-1, 4, 256]         262,400\n",
      "          Dropout-91               [-1, 4, 256]               0\n",
      "      FeedForward-92               [-1, 4, 256]               0\n",
      "          PreNorm-93               [-1, 4, 256]               0\n",
      "            Scale-94               [-1, 4, 256]               0\n",
      "        LayerNorm-95               [-1, 4, 256]             512\n",
      "           Linear-96               [-1, 4, 512]         131,072\n",
      "           Linear-97              [-1, 4, 1024]         262,144\n",
      "        Embedding-98                [-1, 4, 64]          65,600\n",
      "           Linear-99               [-1, 4, 256]         131,328\n",
      "         Dropout-100               [-1, 4, 256]               0\n",
      "       Attention-101               [-1, 4, 256]               0\n",
      "         PreNorm-102               [-1, 4, 256]               0\n",
      "       LayerNorm-103               [-1, 4, 256]             512\n",
      "       Rearrange-104               [-1, 256, 4]               0\n",
      "          Conv1d-105              [-1, 1024, 4]         263,168\n",
      "             GLU-106               [-1, 512, 4]               0\n",
      "          Conv1d-107               [-1, 512, 4]          16,384\n",
      " DepthWiseConv1d-108               [-1, 512, 4]               0\n",
      "     BatchNorm1d-109               [-1, 512, 4]           1,024\n",
      "           Swish-110               [-1, 512, 4]               0\n",
      "          Conv1d-111               [-1, 256, 4]         131,328\n",
      "       Rearrange-112               [-1, 4, 256]               0\n",
      "         Dropout-113               [-1, 4, 256]               0\n",
      "ConformerConvModule-114               [-1, 4, 256]               0\n",
      "       LayerNorm-115               [-1, 4, 256]             512\n",
      "          Linear-116              [-1, 4, 1024]         263,168\n",
      "           Swish-117              [-1, 4, 1024]               0\n",
      "         Dropout-118              [-1, 4, 1024]               0\n",
      "          Linear-119               [-1, 4, 256]         262,400\n",
      "         Dropout-120               [-1, 4, 256]               0\n",
      "     FeedForward-121               [-1, 4, 256]               0\n",
      "         PreNorm-122               [-1, 4, 256]               0\n",
      "           Scale-123               [-1, 4, 256]               0\n",
      "       LayerNorm-124               [-1, 4, 256]             512\n",
      "  ConformerBlock-125               [-1, 4, 256]               0\n",
      "          Linear-126                    [-1, 1]           1,025\n",
      "         Sigmoid-127                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,936,459\n",
      "Trainable params: 11,936,459\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.77\n",
      "Params size (MB): 45.53\n",
      "Estimated Total Size (MB): 47.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net_D = Discriminator()\n",
    "summary(net_D, (1, 128, 44))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ff51a",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec49456",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed363fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "optimizerD = optim.Adam(net_D.parameters(),lr=lr,betas=(beta1,beta2))\n",
    "optimizerG = optim.Adam(net_G.parameters(),lr=lr,betas=(beta1,beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1086ef47",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76d80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "ite = 0\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a4b56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gに入力するノイズ\n",
    "z = torch.Tensor(1, z_dim).uniform_(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cd401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input:  torch.Size([32, 100])\n",
      "0.005950927734375\n",
      "l1: torch.Size([32, 5632])\n",
      "0.00016999244689941406\n",
      "l1 -> reshape: torch.Size([32, 352, 16])\n",
      "blk1-0: torch.Size([32, 352, 16])\n",
      "0.6757700443267822\n",
      "blk2-0 upscale: torch.Size([32, 1408, 4])\n",
      "0.00484013557434082\n",
      "blk2-0: torch.Size([32, 1408, 4])\n",
      "39.72172021865845\n",
      "blk2-1 upscale: torch.Size([32, 5632, 1])\n",
      "0.008321046829223633\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    for ite, data in enumerate(data_loader):\n",
    "        print(ite)\n",
    "        # training Discriminator\n",
    "        # maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        \n",
    "        ## Train with all-real batch\n",
    "        net_D.zero_grad()\n",
    "        labels = torch.full((data.size()[0],), real_label, dtype=torch.float, device=device)\n",
    "        output = net_D(data.unsqueeze(1)).view(-1)\n",
    "        err_D_real = loss_function(output, labels)\n",
    "        err_D_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        ## Train with all-fake batch\n",
    "        noise = torch.randn(batch_size, z_dim)\n",
    "        fake = net_G(noise)\n",
    "        labels.fill_(fake_label)\n",
    "        output = net_D(fake.detach()).view(-1)\n",
    "        err_D_fake = loss_function(output, label)\n",
    "        err_D_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        \n",
    "        err_D = err_D_real + err_D_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tD(x): %.4f\\t'\n",
    "              % (epoch, num_epochs, ite, len(dataloader), err_D.item(), D_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a4cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ConformerGAN",
   "language": "python",
   "name": "conformergan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
